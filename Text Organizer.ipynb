{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Your Text Data By Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a text organizer I made for a client as part of an automation project. It splits an excel spreadsheet into multiple sheets by the keywords it finds. I would be happy to share my other projects (mostly machine learning) privately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import MWETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = pd.ExcelFile('IT Investments.xlsx')\n",
    "itinv = it.parse('Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "header = itinv.loc[0,:]\n",
    "itinv.columns = header\n",
    "itinv = itinv.drop(itinv.index[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "itinv['Investment Description']= itinv['Investment Description'].fillna('none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "itinv['comb']= itinv['Investment ID'].astype(str) + ' ' + itinv['Investment'] + ' ' + itinv['Investment Description'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ngrams(text,ngram=1,stop=True):\n",
    "    stop = set(stopwords.words('english')) if stop else {}\n",
    "    token = [token for token in text.lower().split(\" \") if token != \"\" if token not in stop]\n",
    "    words = zip(*[token[i:] for i in range(ngram)])\n",
    "    ngram = [\" \".join(ngram) for ngram in words]\n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IT Investments Unigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_unigrams = defaultdict(int)\n",
    "description_unigrams = defaultdict(int)\n",
    "comb_unigrams = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in itinv['Investment'].astype(str):\n",
    "    for words in gen_ngrams(text):\n",
    "        investment_unigrams[words]+=1\n",
    "\n",
    "for text in itinv['Investment Description'].astype(str):\n",
    "    for words in gen_ngrams(text):\n",
    "        description_unigrams[words]+=1\n",
    "\n",
    "for text in itinv['comb'].astype(str):\n",
    "    for words in gen_ngrams(text):\n",
    "        comb_unigrams[words]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "investments_unigrams_df = pd.DataFrame(sorted(investment_unigrams.items(),key= lambda x: x[1],reverse=True)) \n",
    "descriptions_unigrams_df = pd.DataFrame(sorted(description_unigrams.items(),key= lambda x: x[1],reverse=True))\n",
    "comb_unigrams_df = pd.DataFrame(sorted(comb_unigrams.items(),key= lambda x: x[1],reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IT Investment Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_bigrams = defaultdict(int)\n",
    "description_bigrams = defaultdict(int)\n",
    "comb_bigrams = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in itinv['Investment'].astype(str):\n",
    "    for words in gen_ngrams(text,2):\n",
    "        investment_bigrams[words]+=1\n",
    "\n",
    "for text in itinv['Investment Description'].astype(str):\n",
    "    for words in gen_ngrams(text,2):\n",
    "        description_bigrams[words]+=1\n",
    "        \n",
    "for text in itinv['comb'].astype(str):\n",
    "    for words in gen_ngrams(text,2):\n",
    "        comb_bigrams[words]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "investments_bigrams_df = pd.DataFrame(sorted(investment_bigrams.items(),key= lambda x: x[1],reverse=True)) \n",
    "descriptions_bigrams_df = pd.DataFrame(sorted(description_bigrams.items(),key= lambda x: x[1],reverse=True))\n",
    "comb_bigrams_df = pd.DataFrame(sorted(comb_bigrams.items(),key= lambda x: x[1],reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IT Investment Trigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "investment_trigrams = defaultdict(int)\n",
    "description_trigrams = defaultdict(int)\n",
    "comb_trigrams = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in itinv['Investment'].astype(str):\n",
    "    for words in gen_ngrams(text,3):\n",
    "        investment_trigrams[words]+=1\n",
    "\n",
    "for text in itinv['Investment Description'].astype(str):\n",
    "    for words in gen_ngrams(text,3):\n",
    "        description_trigrams[words]+=1\n",
    "        \n",
    "for text in itinv['comb'].astype(str):\n",
    "    for words in gen_ngrams(text,3):\n",
    "        comb_trigrams[words]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "investments_trigrams_df = pd.DataFrame(sorted(investment_trigrams.items(),key= lambda x: x[1],reverse=True)) \n",
    "descriptions_trigrams_df = pd.DataFrame(sorted(description_trigrams.items(),key= lambda x: x[1],reverse=True))\n",
    "comb_trigrams_df = pd.DataFrame(sorted(comb_trigrams.items(),key= lambda x: x[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "itinvestments_ngrams = pd.concat([investments_unigrams_df,descriptions_unigrams_df,comb_unigrams_df,\n",
    "                                  investments_bigrams_df,descriptions_bigrams_df,comb_bigrams_df,\n",
    "                                investments_trigrams_df,descriptions_trigrams_df,comb_trigrams_df], axis=1)\n",
    "itinvestments_ngrams.columns = ['inv_unigrams','unigram_count','desc_unigrams','unigram_count','comb_unigrams','unigram_count',\n",
    "                                  'inv_bigrams','bigram_count','desc_bigrams','bigram_count','comb_bigrams','bigram_count',\n",
    "                                'inv_trigrams','trigram_count','desc_trigrams','trigram_count','comb_trigrams','trigram_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "itinvestments_ngrams.to_excel('keyword count.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spreadsheet Sheet 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_security_mwe = [('mwe','is','optional')]\n",
    "it_security_words = ['keyword','keywords']\n",
    "\n",
    "\n",
    "security_tokens_mwe = MWETokenizer(it_security_mwe)\n",
    "it_comb = itinv['comb']\n",
    "row = 0\n",
    "security_id_rownum = []\n",
    "for i in it_comb.astype(str):\n",
    "    row+=1\n",
    "    security_tokens = security_tokens_mwe.tokenize(i.lower().split())\n",
    "    for invwords in security_tokens:\n",
    "        for swords in it_security_words:\n",
    "            if invwords == swords and row not in security_id_rownum:\n",
    "                security_id_rownum.append(row)\n",
    "                \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "securityinvids = itinv['Investment ID'][security_id_rownum]\n",
    "securityinvs = itinv['Investment'][security_id_rownum]\n",
    "securityinvdesc= itinv['Investment Description'][security_id_rownum]\n",
    "securityids = securityinvids.to_frame()\n",
    "securityinvest = securityinvs.to_frame()\n",
    "securitydesc = securityinvdesc.to_frame()\n",
    "security_df = pd.concat([securityids,securityinvest,securitydesc],axis=1,ignore_index=True)\n",
    "security_df.columns = ['Investment ID','Investment','Investment Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spreadsheet Sheet 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_dworkspace_mwe = [('mwe','is','optional')]\n",
    "it_dworkspace_words = ['keyword','keywords']\n",
    "\n",
    "\n",
    "dworkspace_tokens_mwe = MWETokenizer(it_dworkspace_mwe)\n",
    "it_comb = itinv['comb']\n",
    "row = 0\n",
    "dworkspace_id_rownum = []\n",
    "for i in it_comb.astype(str):\n",
    "    row+=1\n",
    "    dworkspace_tokens = dworkspace_tokens_mwe.tokenize(i.lower().split())\n",
    "    for invwords in dworkspace_tokens:\n",
    "        for dwwords in it_dworkspace_words:\n",
    "            if invwords == dwwords and row not in dworkspace_id_rownum:\n",
    "                dworkspace_id_rownum.append(row)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dworkspaceinvids = itinv['Investment ID'][dworkspace_id_rownum]\n",
    "dworkspaceinvs = itinv['Investment'][dworkspace_id_rownum]\n",
    "dworkspaceinvdesc= itinv['Investment Description'][dworkspace_id_rownum]\n",
    "dworkspaceids = dworkspaceinvids.to_frame()\n",
    "dworkspaceinvest = dworkspaceinvs.to_frame()\n",
    "dworkspacedesc = dworkspaceinvdesc.to_frame()\n",
    "dworkspace_df = pd.concat([dworkspaceids,dworkspaceinvest,dworkspacedesc],axis=1,ignore_index=True)\n",
    "dworkspace_df.columns = ['Investment ID','Investment','Investment Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spreadsheet Sheet 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_itautomation_mwe = [('mwe','is','optional')]\n",
    "it_itautomation_words = ['keyword','keywords']\n",
    "\n",
    "\n",
    "itautomation_tokens_mwe = MWETokenizer(it_itautomation_mwe)\n",
    "it_comb = itinv['comb']\n",
    "row = 0\n",
    "itautomation_id_rownum = []\n",
    "for i in it_comb.astype(str):\n",
    "    row+=1\n",
    "    itautomation_tokens = itautomation_tokens_mwe.tokenize(i.lower().split())\n",
    "    for invwords in itautomation_tokens:\n",
    "        for itautowords in it_itautomation_words:\n",
    "            if invwords == itautowords and row not in itautomation_id_rownum:\n",
    "                itautomation_id_rownum.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "itautomationinvids = itinv['Investment ID'][itautomation_id_rownum]\n",
    "itautomationinvs = itinv['Investment'][itautomation_id_rownum]\n",
    "itautomationinvdesc= itinv['Investment Description'][itautomation_id_rownum]\n",
    "itautomationids = itautomationinvids.to_frame()\n",
    "itautomationinvest = itautomationinvs.to_frame()\n",
    "itautomationdesc = itautomationinvdesc.to_frame()\n",
    "itautomation_df = pd.concat([itautomationids,itautomationinvest,itautomationdesc],axis=1,ignore_index=True)\n",
    "itautomation_df.columns = ['Investment ID','Investment','Investment Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spreadsheet Sheet 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_computestore_mwe = [('mwe','is','optional')]\n",
    "it_computestore_words = ['keyword','keywords']\n",
    "\n",
    "\n",
    "computestore_tokens_mwe = MWETokenizer(it_computestore_mwe)\n",
    "it_comb = itinv['comb']\n",
    "row = 0\n",
    "computestore_id_rownum = []\n",
    "for i in it_comb.astype(str):\n",
    "    row+=1\n",
    "    computestore_tokens = computestore_tokens_mwe.tokenize(i.lower().split())\n",
    "    for invwords in computestore_tokens:\n",
    "        for compstrwords in it_computestore_words:\n",
    "            if invwords == compstrwords and row not in computestore_id_rownum:\n",
    "                computestore_id_rownum.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "computestoreinvids = itinv['Investment ID'][computestore_id_rownum]\n",
    "computestoreinvs = itinv['Investment'][computestore_id_rownum]\n",
    "computestoreinvdesc= itinv['Investment Description'][computestore_id_rownum]\n",
    "computestoreids = computestoreinvids.to_frame()\n",
    "computestoreinvest = computestoreinvs.to_frame()\n",
    "computestoredesc = computestoreinvdesc.to_frame()\n",
    "compute_store_df = pd.concat([computestoreids,computestoreinvest,computestoredesc],axis=1,ignore_index=True)\n",
    "compute_store_df.columns = ['Investment ID','Investment','Investment Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spreadsheet Sheet 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_network_mwe = [('mwe','is','optional')]\n",
    "it_network_words = ['keyword', 'keywords']\n",
    "\n",
    "\n",
    "network_tokens_mwe = MWETokenizer(it_network_mwe)\n",
    "it_comb = itinv['comb']\n",
    "row = 0\n",
    "network_id_rownum = []\n",
    "for i in it_comb.astype(str):\n",
    "    row+=1\n",
    "    network_tokens = network_tokens_mwe.tokenize(i.lower().split())\n",
    "    for invwords in network_tokens:\n",
    "        for networds in it_network_words:\n",
    "            if invwords == networds and row not in network_id_rownum:\n",
    "                network_id_rownum.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "networkinvids = itinv['Investment ID'][network_id_rownum]\n",
    "networkinvs = itinv['Investment'][network_id_rownum]\n",
    "networkinvdesc= itinv['Investment Description'][network_id_rownum]\n",
    "networkids = networkinvids.to_frame()\n",
    "networkinvest = networkinvs.to_frame()\n",
    "networkdesc = networkinvdesc.to_frame()\n",
    "network_df = pd.concat([networkids,networkinvest,networkdesc],axis=1,ignore_index=True)\n",
    "network_df.columns = ['Investment ID','Investment','Investment Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_rows = []\n",
    "used_ids_rows = security_id_rownum + dworkspace_id_rownum + itautomation_id_rownum + computestore_id_rownum + network_id_rownum\n",
    "total_ids = list(range(1,(len(itinv.index)+1)))\n",
    "for i in total_ids:\n",
    "    if i not in used_ids_rows:\n",
    "        unmatched_rows.append(i)\n",
    "        \n",
    "\n",
    "unmatchedinvids = itinv['Investment ID'][unmatched_rows]\n",
    "unmatchedinvs = itinv['Investment'][unmatched_rows]\n",
    "unmatchedinvdesc= itinv['Investment Description'][unmatched_rows]\n",
    "unmatchedids = unmatchedinvids.to_frame()\n",
    "unmatchedinvest = unmatchedinvs.to_frame()\n",
    "unmatcheddesc = unmatchedinvdesc.to_frame()\n",
    "unmatched_df = pd.concat([unmatchedids,unmatchedinvest,unmatcheddesc],axis=1,ignore_index=True)\n",
    "unmatched_df.columns = ['Investment ID','Investment','Investment Description'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('IT Investment Directory.xlsx') as writer:\n",
    "    security_df.to_excel(writer,sheet_name=\"Security\")\n",
    "    dworkspace_df.to_excel(writer,sheet_name=\"Digital Workspace\")\n",
    "    itautomation_df.to_excel(writer,sheet_name=\"IT Automation\")\n",
    "    compute_store_df.to_excel(writer,sheet_name=\"Compute and Store\")\n",
    "    network_df.to_excel(writer,sheet_name=\"Network\")\n",
    "    unmatched_df.to_excel(writer,sheet_name=\"Unmatched Investments\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
